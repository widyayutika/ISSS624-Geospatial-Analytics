---
title: "In-class_Ex2: Spatial Weights and Local Measures of Spatial Association - sfdep methods"
author: "Widya Tantiya Yutika"
date: "25 November 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## **Overview**

This in-class introduces an alternative R package to spdep package. The package is called [**sfdep**](https://sfdep.josiahparry.com/). According to Josiah Parry, the developer of the package, "sfdep builds on the great shoulders of **spdep** package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible."

## Getting Started

### Installing and Loading the R Packages

Five R packages will be used for this in-class exercise, they are: sf, sfdep, tmap, tidyverse, and knitr.

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, install and load **sf**, **tmap**, **sfdep**, **tidyverse** and **knitr** packages into R environment.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
pacman::p_load( sf, sfdep, tmap, tidyverse, knitr)
```

## The Data

For the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:

-   Hunan, a geospatial data set in ESRI shapefile format, and

-   Hunan_2012, an attribute data set in csv format.

## Getting Data in R Environment

### **Importing geospatial data**

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, import *Hunan* shapefile into R environment as an sf data frame.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
hunan <- st_read(dsn = "data/geospatial", layer = "Hunan")
```

### **Importing attribute table**

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, import *Hunan_2012.csv* into R environment as an tibble data frame.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

### Combining both data frame by using left join

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, combine the Hunan sf data frame and Hunan_2012 data frame. Ensure that the output is an sf data frame.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
hunan_GDPPC <- left_join(hunan,hunan2012)%>%
  select(1:4, 7, 15)
```

::: callout-important
In order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)
:::

### **Plotting a choropleth map**

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, plot a choropleth map showing the distribution of GDPPC of Hunan Province.
:::

The choropleth should look similar to ther figure below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
tm_shape(hunan_GDPPC) +
  tm_fill("GDPPC", 
          style = "quantile", 
          palette = "Blues",
          title = "GDPPC") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of GDP per capita by district, Hunan Province",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

## Deriving Continuity Spatial Weights

By and large, there are two types of spatial weights, they are contiguity wights and distance-based weights. In this section, you will learn how to derive contiguity spatial weights by using sfdep.

Two steps are required to derive a contiguity spatial weights, they are:

1.  identifying contiguity neighbour list by [`st_contiguity()`](https://sfdep.josiahparry.com/reference/st_contiguity.html) of **sfdep** package, and

2.  deriving the contiguity spatial weights by using [`st_weights()`](https://sfdep.josiahparry.com/reference/st_weights.html) of **sfdep** package

In this section, we will learn how to derive the contiguity neighbour list and contiguity spatial weights separately. Then, we will learn how to combine both steps into a single process.

### **Identifying** Continuity Spatial Weights: Queen's Method

In the code chunk below [`st_contiguity()`](https://sfdep.josiahparry.com/reference/st_contiguity.html) is used to derive a contiguity neighbour list by using Queen's method.

```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb, style = "W"),
         .before=1)
```

::: callout-note
.before=1 -\> put nb and wt at the front of the tibble dataset
:::

::: callout-important
By default, queen argument is **TRUE**. If you do not specify *queen = FALSE*, this function will return a list of first order neighbours by using the Queen criteria. Rooks method will be used to identify the first order neighbour if queen = FALSE is used.
:::

The code chunk below is used to print the summary of the first lag neighbour list (i.e. nb) .

```{r}
summary(wm_q$nb)
```

The summary report above shows that there are 88 area units in Hunan province. The most connected area unit has 11 neighbours. There are two are units with only one neighbour.

To view the content of the data table, you can either display the output data frame on RStudio data viewer or by printing out the first ten records by using the code chunk below.

```{r}
wm_q
```

The print shows that polygon 1 has five neighbours. They are polygons number 2, 3, 4, 57,and 85.

One of the advantage of **sfdep** over **spdep** is that the output is an sf tibble data frame.

::: callout-note
## Do It Yourself!

Using the steps you learned in previous lesson, display nb_queen sf tibble data frame in a table display.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
kable(head(wm_q,n=10))
```

### **Identify contiguity neighbours: Rooks' method**

::: callout-note
## Do It Yourself!

Using the steps you just learned, derive a contiguity neighbour list using Rooks' method.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
wm_r <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry, queen=FALSE),
         wt = st_weights(nb, style = "W"),
         .before=1)
```

### **Identifying higher order neighbors**

There are times that we need to identify high order contiguity neighbours. To accomplish the task, [`st_nb_lag_cumul()`](https://sfdep.josiahparry.com/reference/st_nb_lag_cumul.html) should be used as shown in the code chunk below.

::: callout-note
## Do It Yourself!

Using the steps you just learned, derive a contiguity neighbour list using lag 2 Queen's method.
:::

```{r}
#| code-fold: true
#| code-summary: "Show the code"
nb2_queen <-  hunan_GDPPC %>% 
  mutate(nb = st_contiguity(geometry),
         nb2 = st_nb_lag_cumul(nb, 2),
         .before = 1)
```

Note that if the order is 2, the result contains both 1st and 2nd order neighbors as shown on the print below.

```{r}
nb2_queen
```

### Computing local Moran's I

In this section, you will learn how to compute Local Moran's I of GDPPC at county level by using [`local_moran()`](https://sfdep.josiahparry.com/reference/local_moran.html) of sfdep package.

```{r}
lisa <- wm_q %>%
  mutate(local_moran = local_moran(
    GDPPC, nb, wt, nsim = 99),
    .before = 1) %>%
  unnest(local_moran)
```

The output of `local_moran()` is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.

-   ii: local moran statistic

-   eii: expectation of local moran statistic; for localmoran_permthe permutation sample means

-   var_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations

-   z_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations

-   p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations

-   p_ii_sim: For `localmoran_perm()`, `rank()` and `punif()` of observed statistic rank for \[0, 1\] p-values using `alternative=`

-   p_folded_sim: the simulation folded \[0, 0.5\] range ranked p-value based on [crand.py](https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b8cadcbecc5e061/esda/crand.py#L211-L213) of pysal

-   skewness: For `localmoran_perm`, the output of e1071::skewness() for the permutation samples underlying the standard deviates

-   kurtosis: For `localmoran_perm`, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.

::: callout-important
[`unnest()`](https://tidyr.tidyverse.org/reference/unnest.html) of **tidyr** package is used to expand a list-column containing data frames into rows and columns.
:::

### **Visualising local Moran's I**

In this code chunk below, tmap functions are used prepare a choropleth map by using value in the *ii* field.

```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 0.8)
```

### **Visualising p-value of local Moran's I**

In the code chunk below, tmap functions are used prepare a choropleth map by using value in the *p_ii_sim* field.

```{r}
tmap_mode("plot")
tm_shape(lisa) +
  tm_fill("p_ii_sim") + 
  tm_borders(alpha = 0.5) +
   tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)
```

::: callout-warning
For p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme.
:::

### **Visualising local Moran's I and p-value**

For effective comparison, it will be better for us to plot both maps next to each other as shown below.

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of GDPPC",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```
